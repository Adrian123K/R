credit_actual <- credit_test$default
kappa <- kappa2(data.frame(credit_actual, credit_pred))$value
return(kappa)
})
str(cv_results)
credit <- read.csv("credit.csv",stringsAsFactors = T)
credit_train <- credit[in_train, ] # 훈련 데이터 구성
credit_test <- credit[-in_train, ] # 테스트 데이터 구성
credit <- read.csv("credit.csv",stringsAsFactors = T)
set.seed(123)
random_ids <- order(runif(800))
credit <- credit[random_ids[1:800],]
credit_train <- credit[in_train, ] # 훈련 데이터 구성
credit_test <- credit[-in_train, ] # 테스트 데이터 구성
nrow(credit_train)
nrow(credit_test)
credit <- read.csv("credit.csv",stringsAsFactors = T)
set.seed(123)
random_ids <- order(runif(800))
credit <- credit[random_ids[1:800],]
nrow(credit_train) #601
nrow(credit_test) #199
in_train <- createDataPartition(credit$default, p = 0.75, list = FALSE)
credit_train <- credit[in_train, ] # 훈련 데이터 구성
credit_test <- credit[-in_train, ] # 테스트 데이터 구성
nrow(credit_train) #601
nrow(credit_test) #199
folds <- createFolds(credit$default, k = 10)
cv_results <- lapply(folds, function(x) {
credit_train <- credit[-x, ]
credit_test <- credit[x, ]
credit_model <- C5.0(default ~ ., data = credit_train)
credit_pred <- predict(credit_model, credit_test)
credit_actual <- credit_test$default
kappa <- kappa2(data.frame(credit_actual, credit_pred))$value
return(kappa)
})
str(cv_results)
credit <- read.csv("credit.csv",stringsAsFactors = T)
set.seed(123)
random_ids <- order(runif(800))
credit <- credit[random_ids[1:800],]
in_train <- createDataPartition(credit$default, p = 0.7, list = FALSE)
credit_train <- credit[in_train, ] # 훈련 데이터 구성
credit_test <- credit[-in_train, ] # 테스트 데이터 구성
nrow(credit_train) #601
nrow(credit_test) #199
folds <- createFolds(credit$default, k = 10)
in_train <- createDataPartition(credit$default, p = 0.75, list = FALSE)
credit_train <- credit[in_train, ] # 훈련 데이터 구성
credit_test <- credit[-in_train, ] # 테스트 데이터 구성
nrow(credit_train) #601
nrow(credit_test) #199
folds <- createFolds(credit$default, k = 10)
cv_results <- lapply(folds, function(x) {
credit_train <- credit[-x, ]
credit_test <- credit[x, ]
credit_model <- C5.0(default ~ ., data = credit_train)
credit_pred <- predict(credit_model, credit_test)
credit_actual <- credit_test$default
kappa <- kappa2(data.frame(credit_actual, credit_pred))$value
return(kappa)
})
str(cv_results)
str(cv_results)
cv_results <- lapply(folds, function(x) {
credit_train <- credit[-x, ]
credit_test <- credit[x, ]
credit_model <- C5.0(default ~ ., data = credit_train)
credit_pred <- predict(credit_model, credit_test)
credit_actual <- credit_test$default
kappa <- kappa2(data.frame(credit_actual, credit_pred))$value
return(kappa)
})
str(cv_results)
head(credit$default)
in_train <- createDataPartition(credit$default,times=2, p = 0.8, list = FALSE)
in_train
in_train <- createDataPartition(credit$default,p = 0.8, list = FALSE)
in_train
credit <- read.csv("credit.csv",stringsAsFactors = T)
in_train <- createDataPartition(credit$default,p = 0.8, list = FALSE)
in_train
credit <- read.csv("credit.csv",stringsAsFactors = T)
#set.seed(123)
#random_ids <- order(runif(800))
#credit <- credit[random_ids[1:800],]
in_train <- createDataPartition(credit$default,p = 0.8, list = FALSE)
in_train
credit_train <- credit[in_train, ] # 훈련 데이터 구성
credit_test <- credit[-in_train, ] # 테스트 데이터 구성
nrow(credit_train) #601
nrow(credit_test) #199
folds <- createFolds(credit$default, k = 10)
cv_results <- lapply(folds, function(x) {
credit_train <- credit[-x, ]
credit_test <- credit[x, ]
credit_model <- C5.0(default ~ ., data = credit_train)
credit_pred <- predict(credit_model, credit_test)
credit_actual <- credit_test$default
kappa <- kappa2(data.frame(credit_actual, credit_pred))$value
return(kappa)
})
str(cv_results)
in_train <- createDataPartition(credit$default,p = 0.75, list = FALSE)
credit_train <- credit[in_train, ] # 훈련 데이터 구성
credit_test <- credit[-in_train, ] # 테스트 데이터 구성
nrow(credit_train) #601
nrow(credit_test) #199
credit <- read.csv("credit.csv",stringsAsFactors = T)
in_train <- createDataPartition(credit$default,p = 0.75, list = FALSE)
in_train
credit_train <- credit[in_train, ] # 훈련 데이터 구성
credit_test <- credit[-in_train, ] # 테스트 데이터 구성
nrow(credit_train) #601
nrow(credit_test) #199
folds <- createFolds(credit$default, k = 10)
cv_results <- lapply(folds, function(x) {
credit_train <- credit[-x, ]
credit_test <- credit[x, ]
credit_model <- C5.0(default ~ ., data = credit_train)
credit_pred <- predict(credit_model, credit_test)
credit_actual <- credit_test$default
kappa <- kappa2(data.frame(credit_actual, credit_pred))$value
return(kappa)
})
str(cv_results)
mean(unlist(cv_results))
credit <- read.csv("credit.csv")
set.seed(123)
cv_results <- lapply(folds, function(x) {
credit_train <- credit[-x, ]
credit_test <- credit[x, ]
credit_model <- C5.0(default ~ ., data = credit_train)
credit_pred <- predict(credit_model, credit_test)
credit_actual <- credit_test$default
kappa <- kappa2(data.frame(credit_actual, credit_pred))$value
return(kappa)
})
str(cv_results)
mean(unlist(cv_results))
# 296
credit <- read.csv("credit.csv",stringsAsFactors = T)
in_train <- createDataPartition(credit$default,p = 0.75, list = FALSE)
credit_train <- credit[in_train, ]
credit_test <- credit[-in_train, ]
folds <- createFolds(credit$default, k = 10)
cv_results <- lapply(folds, function(x) {
credit_train <- credit[-x, ]
credit_test <- credit[x, ]
credit_model <- C5.0(default ~ ., data = credit_train)
credit_pred <- predict(credit_model, credit_test)
credit_actual <- credit_test$default
x <- data.frame(credit_actual, credit_pred)
rs <- sum(x$credit_actual==x$credit_pred)/length(x$credit_actual==x$credit_pred)
return(rs)
})
cv_results
str(cv_results)
# 296
credit <- read.csv("credit.csv",stringsAsFactors = T)
set.seed(123)
folds <- createFolds(credit$default, k = 10)
cv_results <- lapply(folds, function(x) {
credit_train <- credit[-x, ]
credit_test <- credit[x, ]
credit_model <- C5.0(default ~ ., data = credit_train)
credit_pred <- predict(credit_model, credit_test)
credit_actual <- credit_test$default
x <- data.frame(credit_actual, credit_pred)
rs <- sum(x$credit_actual==x$credit_pred)/length(x$credit_actual==x$credit_pred)
return(rs)
})
str(cv_results)
# caret 패키지 사용
credit <- read.csv('credit.csv',stringsAsFactors = T)
set.seed(300)
m <- train(default~., data=credit, method='C5.0')
m
p <- predict(m,credit)
table(p,credit$default)
m_test <- train(default~., data=credit, method='C5.0',
metric='kappa',
trControl=ctrl,
truneGrid=grid)
p <- predict(m_test, credit)
p
str(p)
table(p,credit$default)
m_test <- train(default~., data=credit, method='C5.0',
metric='kappa',
trControl=ctrl,
truneGrid=grid)
m <- train(default~., data=credit, method='C5.0',
metric='kappa',
trControl=ctrl,
truneGrid=grid)
m <- train(default~., data=credit,method='C5.0')
ctrl <- trainControl(method='cv',number=10,selectionFunction='oneSE')
grid <- expand.grid(.model='tree',
.trials=c(1,5,10,15,20,25,30,35), # trials를 8개로 제한하겠다
.winnow='FALSE')
p <- predict(m, credit)
table(p,credit$default)
m <- train(default~., data=credit, method='C5.0',
metric='kappa',
trControl=ctrl,
truneGrid=grid)
ret_err <- function(n,err) {
sum <- 0
for(i in floor(n/2):n) {
sum <- sum + choose(n,i) * err^i * (1-err)^(n-i)
}
sum
}
for(j in 1:60) {
err <- ret_err(j , 0.4)
cat(j,'--->',1-err,'\n')
if(1-err >= 0.9) break
}
install.packages('ipred')
install.packages("ipred")
library(ipred)
set.seed(300)
credit <- read.csv('credit.csv',stringsAsFactors = T)
set.seed(300)
mybag <- bagging(default~., data=credit, nbagg=25) # nbagg=25 : 앙상블에 사용되는  bag의 개수
credit_pred <- predict(mybag, credit)
credit_pred <- predict(mybag, credit)
table(credit_pred,credit$default)
prop.table(table(credit_pred==credit$default))
# 299
mybag <- bagging(default~., data=credit, nbagg=50)
credit_pred <- predict(mybag, credit)
table(credit_pred,credit$default)
prop.table(table(credit_pred==credit$default))
install.packages('adabag')
library(adabag)
set.seed(300)
credit <- read.csv('credit.csv',stringsAsFactors = T)
m_adaboost <- boosting(default~., data=credit)
p_adaboost <- predict(m_adaboost, credit)
head(p_adaboost$class)
p_adaboost$confusion
table(p_adaboost$class,credit$default)
mushroom <- read.csv('mushrooms.csv',stringsAsFactors = T)
str(mushroom)
m_adaboost <- boosting(type~., data=mushroom)
p_adaboost <- predict(m_adaboost, mushroom)
table(p_adaboost$class,credit$type)
p_adaboost
table(p_adaboost$class,mushroom$type)
#install.packages("caret")
install.packages("doParallel")
install.packages("kernlab")
install.packages("lattice")
install.packages("lattice")
library(ggplot2)
library(lattice)
library(kernlab)
library(caret)
library(doParallel)
cl <- makeCluster(detectCores())
registerDoParallel(cl)
# Load the MNIST digit recognition dataset into R
# http://yann.lecun.com/exdb/mnist/
# assume you have all 4 files and gunzip'd them
# creates train$n, train$x, train$y  and test$n, test$x, test$y
# e.g. train$x is a 60000 x 784 matrix, each row is one digit (28x28)
# call:  show_digit(train$x[5,])   to see a digit.
# brendan o'connor - gist.github.com/39760 - anyall.org
load_mnist <- function() {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
ret$n = readBin(f,'integer',n=1,size=4,endian='big')
nrow = readBin(f,'integer',n=1,size=4,endian='big')
ncol = readBin(f,'integer',n=1,size=4,endian='big')
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
y
}
train <<- load_image_file('train-images.idx3-ubyte')
test <<- load_image_file('t10k-images.idx3-ubyte')
train$y <<- load_label_file('train-labels.idx1-ubyte')
test$y <<- load_label_file('t10k-labels.idx1-ubyte')
}
show_digit <- function(arr784, col=gray(12:1/12), ...) {
image(matrix(arr784, nrow=28)[,28:1], col=col, ...)
}
train <- data.frame()
test <- data.frame()
# Load data.
load_mnist()
# Normalize: X = (X - min) / (max - min) => X = (X - 0) / (255 - 0) => X = X / 255.
train$x <- train$x / 255
# Setup training data with digit and pixel values with 60/40 split for train/cv.
inTrain = data.frame(y=train$y, train$x)
inTrain$y <- as.factor(inTrain$y)
trainIndex = createDataPartition(inTrain$y, p = 0.60,list=FALSE)
training = inTrain[trainIndex,]
cv = inTrain[-trainIndex,]
# SVM. 95/94.
fit <- train(y ~ ., data = head(training, 1000), method = 'svmRadial', tuneGrid = data.frame(sigma=0.0107249, C=1))
results <- predict(fit, newdata = head(cv, 1000))
results
confusionMatrix(results, head(cv$y, 1000))
show_digit(as.matrix(training[5,2:785]))
# Predict the digit.
predict(fit, newdata = training[5,])
# Check the actual answer for the digit.
training[5,1]
cl <- makeCluster(detectCores())
registerDoParallel(cl)
load_mnist <- function() {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
ret$n = readBin(f,'integer',n=1,size=4,endian='big')
nrow = readBin(f,'integer',n=1,size=4,endian='big')
ncol = readBin(f,'integer',n=1,size=4,endian='big')
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
y
}
train <<- load_image_file('train-images.idx3-ubyte')
test <<- load_image_file('t10k-images.idx3-ubyte')
train$y <<- load_label_file('train-labels.idx1-ubyte')
test$y <<- load_label_file('t10k-labels.idx1-ubyte')
}
show_digit <- function(arr784, col=gray(12:1/12), ...) {
image(matrix(arr784, nrow=28)[,28:1], col=col, ...)
}
train <- data.frame()
test <- data.frame()
load_mnist()
library(ggplot2)
library(lattice)
library(kernlab)
library(caret)
library(doParallel)
getwd()
load_mnist()
train$x <- train$x / 255
inTrain = data.frame(y=train$y, train$x)
inTrain$y <- as.factor(inTrain$y)
trainIndex = createDataPartition(inTrain$y, p = 0.60,list=FALSE)
training = inTrain[trainIndex,]
cv = inTrain[-trainIndex,]
fit <- train(y ~ ., data = head(training, 1000), method = 'svmRadial', tuneGrid = data.frame(sigma=0.0107249, C=1))
results <- predict(fit, newdata = head(cv, 1000))
results
confusionMatrix(results, head(cv$y, 1000))
show_digit(as.matrix(training[5,2:785]))
# Predict the digit.
predict(fit, newdata = training[5,])
# Check the actual answer for the digit.
training[5,1]
show_digit(as.matrix(training[5,2:785]))
body <- read.csv("kbody2.csv", header = F)
# 라이브러리 불러옴
library(e1071)
# na값 제거
body1 <- na.omit(body)
# 컬럼명 줌
colnames(body1) <- c("gender", "age", "height", "chest", "heory", "bae", "ass", "kyeo",
"face_vertical", "head", "bone", "body_fat", "body_water",
"protein", "mineral", "body_fat_per", "bae_fat_per", "work", "bae_fat_test",
"work_test")
# 랜덤시드 생성
set.seed(12345)
# 셔플
body_ran <- body1[order(runif(12894)), ]
# 트레이닝셋 80%
body_train <- body_ran[1:10314, ]
# 테스트셋 20%
body_test <- body_ran[10315:12894, ]
body_svm <- svm(work_test~., data = body_train, kernel="linear")
body_svm
body <- read.csv("kbody2.csv", header = F,stringsAsFactors = T)
library(e1071)
body1 <- na.omit(body)
colnames(body1) <- c("gender", "age", "height", "chest", "heory", "bae", "ass", "kyeo",
"face_vertical", "head", "bone", "body_fat", "body_water",
"protein", "mineral", "body_fat_per", "bae_fat_per", "work", "bae_fat_test",
"work_test")
set.seed(12345)
body_ran <- body1[order(runif(12894)), ]
body_train <- body_ran[1:10314, ]
body_test <- body_ran[10315:12894, ]
body_svm <- svm(work_test~., data = body_train, kernel="linear")
body_svm
p <- predict(body_svm, body_test, type="class")
p
table(p, body_test[, 20])
mean(p == body_test[, 20])
# 301
body_svm <- svm(work_test~., data = body_train, kernel='rbf')
body_svm
# 301
body_svm <- svm(work_test~., data = body_train, kernel='radial')
body_svm
p <- predict(body_svm, body_test, type="class")
p
table(p, body_test[, 20])
mean(p == body_test[, 20])
# 301
body_svm <- svm(work_test~., data = body_train, kernel='RBF')
# 301
body_svm <- svm(work_test~., data = body_train, kernel='rbf')
# 301
body_svm <- svm(work_test~., data = body_train, kernel='polynomia')
p <- predict(body_svm, body_test, type="class")
table(p, body_test[, 20])
mean(p == body_test[, 20])
# 301
body_svm <- svm(work_test~., data = body_train, kernel='radial')
p <- predict(body_svm, body_test, type="class")
table(p, body_test[, 20])
mean(p == body_test[, 20])
tune(svm, work_test~., data = body_train)
tune(svm, work_test~., data = body_train, cost=10^(-1:2), gamma=c(.5,1,2))
ctrl <- trainControl(method='cv', number=10)
bagctl <- bagControl(fit=svmBag$fit,
predict=svmBag$pred,
aggregate=svmBag$aggregate)
set.seed(300)
svmbat <- train(work_test~., data=body_train, 'bag',
trControl=ctrl, bagControl=bagctrl)
svmbat <- train(work_test~., data=body_train,
trControl=ctrl, bagControl=bagctrl)
ctrl <- trainControl(method='cv', number=10)
bagctrl <- bagControl(fit=svmBag$fit,
predict=svmBag$pred,
aggregate=svmBag$aggregate)
set.seed(300)
svmbat <- train(work_test~., data=body_train,
trControl=ctrl, bagControl=bagctrl)
svmbat <- train(work_test~., data=body_train,'bag'
trControl=ctrl, bagControl=bagctrl)
svmbat <- train(work_test~., data=body_train,'bag',
trControl=ctrl, bagControl=bagctrl)
body <- read.csv("kbody2.csv", header = F,stringsAsFactors = T)
body1 <- na.omit(body)
colnames(body1) <- c("gender", "age", "height", "chest", "heory", "bae", "ass", "kyeo",
"face_vertical", "head", "bone", "body_fat", "body_water",
"protein", "mineral", "body_fat_per", "bae_fat_per", "work", "bae_fat_test",
"work_test")
set.seed(300)
ctrl <- trainControl(method='cv', number=10)
bagctrl <- bagControl(fit=svmBag$fit,
predict=svmBag$pred,
aggregate=svmBag$aggregate)
svmbat <- train(work_test~., data=body_train,,
trControl=ctrl, bagControl=bagctrl)
body_train <- body_ran[1:10314, ]
body_test <- body_ran[10315:12894, ]
svmbat <- train(work_test~., data=body_train,,
trControl=ctrl, bagControl=bagctrl)
svmbat <- train(work_test~., data=body_train,
trControl=ctrl, bagControl=bagctrl)
svmbat <- train(work_test~., data=body_train,method='bag',
trControl=ctrl, bagControl=bagctrl)
svmbat <- train(work_test~., data=body_train, method='treebag',
trControl=ctrl, bagControl=bagctrl)
# caret
ctrl <- trainControl(method='cv', number=10)
bagctrl <- bagControl(fit=svmBag$fit,
predict=svmBag$pred,
aggregate=svmBag$aggregate)
svmbat <- train(work_test~., data=body_train, trControl=ctrl, bagControl=bagctrl)
install.packages('parallel')
install.packages("parallel")
library(parallel)
a <- rnorm(1000000)
a
system.time(a <- rnorm(1000000))
system.time(l2<-unlist(mclapply(1:2, function(x) {
rnorm(5000000) } , mc.cores=1 )))
# 리눅스에서 수행
#* foreach 와 doParallel 를 이용한 병렬 작업 (p543)
#1. 병렬처리 안했을때
library(foreach)
system.time(l4<- foreach(i =1:400, .combine='c')
%do% rnorm(250000))
# 2. 병렬처리 했을때
library(doParallel)
registerDoParallel(cores=4)
system.time(l4<- foreach(i =1:400, .combine='c')
%do% rnorm(250000))
system.time(l2<-unlist(mclapply(1:2, function(x) {
rnorm(5000000) } , mc.cores=2 )))
