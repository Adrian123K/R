print('이 환자는 독감 환자가 아닙니다.')
}
print(model)
}
naive_fun()
naive_fun<-function(){
library(e1071)
flu <- read.csv("flu.csv", header=T, stringsAsFactors=TRUE)
train <- flu[1:nrow(flu),-1]
model <- naiveBayes(train[,1:4], train$flue , laplace=0)
q1 <- readline(prompt = '오한이 있습니까? Y/N')
q2 <- readline(prompt = '콧물이 있습니까? Y/N')
q3 <- readline(prompt = '두통이 있습니까? MILD/STRONG/NO')
q4 <- readline(prompt = '오한이 있습니까? Y/N')
test <- c(q1,q2,q3,q4)
result <- predict( model, test)
if (result=='Y'){
print('이 환자는 독감 환자 입니다.')
} else {
print('이 환자는 독감 환자가 아닙니다.')
}
}
naive_fun()
naive_fun<-function(){
library(e1071)
flu <- read.csv("flu.csv", header=T, stringsAsFactors=TRUE)
train <- flu[1:nrow(flu),-1]
model <- naiveBayes(train[,1:4], train$flue , laplace=0)
q1 <- readline(prompt = '오한이 있습니까? Y/N ')
q2 <- readline(prompt = '콧물이 있습니까? Y/N ')
q3 <- readline(prompt = '두통이 있습니까? MILD/STRONG/NO ')
q4 <- readline(prompt = '오한이 있습니까? Y/N ')
test <- data.frame(chills=q1,runny_nose=q2,headache=q3,fever=q4)
result <- predict( model, test)
if (result=='Y'){
print('이 환자는 독감 환자 입니다.')
} else {
print('이 환자는 독감 환자가 아닙니다.')
}
}
naive_fun()
naive_fun<-function(){
library(e1071)
flu <- read.csv("flu.csv", header=T, stringsAsFactors=TRUE)
train <- flu[1:nrow(flu),-1]
model <- naiveBayes(train[,1:4], train$flue , laplace=0)
fname <- file.choose()
test <- read.csv(fname, header=T, stringsAsFactor=F )
result <- predict( model, test, type='raw')
if (result=='Y'){
print('이 환자는 독감 환자 입니다.')
} else {
print('이 환자는 독감 환자가 아닙니다.')
}
}
naive_fun()
naive_fun<-function(){
library(e1071)
flu <- read.csv("flu.csv", header=T, stringsAsFactors=TRUE)
train <- flu[1:nrow(flu),-1]
model <- naiveBayes(train[,1:4], train$flue , laplace=0)
fname <- file.choose()
test <- read.csv(fname, header=T, stringsAsFactor=F )
result <- predict( model, test, type='raw')
print(result)
}
naive_fun()
naive_fun<-function(){
library(e1071)
flu <- read.csv("flu.csv", header=T, stringsAsFactors=TRUE)
train <- flu[1:nrow(flu),-1]
model <- naiveBayes(train[,1:4], train$flue , laplace=0)
fname <- file.choose()
test <- read.csv(fname, header=T, stringsAsFactor=F )
result <- predict( model, test, type='raw')
print(result[2]*100)
}
naive_fun()
naive_fun<-function(){
library(e1071)
flu <- read.csv("flu.csv", header=T, stringsAsFactors=TRUE)
train <- flu[1:nrow(flu),-1]
model <- naiveBayes(train[,1:4], train$flue , laplace=0)
fname <- file.choose()
test <- read.csv(fname, header=T, stringsAsFactor=F )
result <- predict( model, test, type='raw')
print(paste(round(result[2]*100,digits=1)),'% 입니다.')
}
naive_fun()
naive_fun<-function(){
library(e1071)
flu <- read.csv("flu.csv", header=T, stringsAsFactors=TRUE)
train <- flu[1:nrow(flu),-1]
model <- naiveBayes(train[,1:4], train$flue , laplace=0)
fname <- file.choose()
test <- read.csv(fname, header=T, stringsAsFactor=F )
result <- predict( model, test, type='raw')
print(paste(round(result[2]*100,digits=1),'% 입니다.'))
}
naive_fun()
(-3/5)*log2(3/5)
(-2/5)*log2(2/5)
(-2/5)*log2(2/5)+(-3/5)*log2(3/5)
(-2/3)*log2(2/3)+(-1/3)*log2(1/3)
my_func <- function() {
library(data.table)
my_scatter <- function() {
fname <- file.choose()
table <- read.csv(fname, header=T, stringsAsFactor=F )
print(data.table(colnames(table)))
xcol_num <- as.numeric(readline('x축 컬럼 번호: '))
ycol_num <- as.numeric(readline('y축 컬럼 번호: '))
xcol <- colnames(table[xcol_num])
ycol <- colnames(table[ycol_num])
xcol2 <- table[,xcol]
ycol2 <- table[,ycol]
plot(xcol2,ycol2,
main=paste(xcol,'과',ycol,'의 산포도 그래프'),lwd=2,
xlab=xcol,ylab=ycol,col='red',pch=21,bg='red')
}
my_hist <- function() {
fname <- file.choose()
table <- read.csv(fname, header=T, stringsAsFactor=F )
print(data.table(colnames(table)))
xcol_num <- as.numeric(readline('x축 컬럼 번호: '))
xcol <- colnames(table[xcol_num])
xcol2 <- table[,xcol]
class1 <- sort(xcol2)
hist(class1 , col="yellow", density=80,      main="히스토그램 정규분포 그래프" )
par(new=T)
plot( class1, dnorm( class1, mean=mean(class1),
sd=sd(class1)),type='l', axes=FALSE, ann=FALSE,   col="red")
}
my_box <- function() {
fname <- file.choose()
table <- read.csv(fname, header=T, stringsAsFactor=F )
print(data.table(colnames(table)))
xcol_num <- as.numeric(readline('x축 컬럼 번호: '))
xcol <- colnames(table[xcol_num])
xcol2 <- table[,xcol]
boxplot(xcol2, col="green", density=80 )
}
knn_fun<-function(){
x <-  "d:/R/wisc_bc_data.csv"
y <-"diagnosis"
k_n <- 21
data1 <- read.csv(x, stringsAsFactors=FALSE)
normalize<-function(x) {
return( (x-min(x))/ ( max(x)-min(x)))
}
data1 <- data1[-1]
ncol1 <- which(colnames(data1)==y)
data1_n <- as.data.frame(lapply(data1[,-ncol1], normalize) )
mm<-round(nrow(data1_n)*2/3)
data1_train <- data1_n[1:mm, ]
data1_test  <- data1_n[(mm+1):nrow(data1_n), ]
data1_train_label <- data1[1:mm,y]
data1_test_label  <- data1[(mm+1):nrow(data1_n),y]
library(class)
result1 <- knn(train=data1_train, test=data1_test,  cl= data1_train_label, k = k_n )
prop.table( table(ifelse(data1[(mm+1):nrow(data1_n),y]==result1,"o","x" )))
fname <- file.choose()
table <- read.csv(fname, header=T, stringsAsFactor=F )
table <- table[-1]
ncol1 <- which(colnames(table)==y)
data1 <- rbind(data1,table)
data1_n <- as.data.frame(lapply(data1[,-ncol1], normalize) )
data2_test <- data1_n[nrow(data1_n),]
result2 <- knn(train=data1_train, test=data2_test,  cl= data1_train_label, k = k_n )
if (result2=='M'){
print('ML 모델이 암환자로 예측 했습니다.')
} else {
print('ML 모델이 정상환자로 예측 했습니다.')
}
}
naive_fun<-function(){
library(e1071)
flu <- read.csv("flu.csv", header=T, stringsAsFactors=TRUE)
train <- flu[1:nrow(flu),-1]
model <- naiveBayes(train[,1:4], train$flue , laplace=0)
q1 <- readline(prompt = '오한이 있습니까? Y/N ')
q2 <- readline(prompt = '콧물이 있습니까? Y/N ')
q3 <- readline(prompt = '두통이 있습니까? MILD/STRONG/NO ')
q4 <- readline(prompt = '오한이 있습니까? Y/N ')
test <- data.frame(chills=q1,runny_nose=q2,headache=q3,fever=q4)
result <- predict( model, test, type='raw')
print(paste('독감 환자일 확률이',round(result[2]*100,digits=1),'% 입니다.'))
}
x1 <- menu( c('산포도 그래프','히스토그램 그래프','사분위수 그래프', '유방암 진단', '독감 진단') ,
title='숫자를 선택하세요: ' )
switch ( x1,
san1 = {   my_scatter()       },
san2 = {   my_hist()          },
san3 = {   my_box()           },
san4 = {   knn_fun()          },
san5 = {   naive_fun()        }
)
}
my_func()
my_func <- function() {
library(data.table)
my_scatter <- function() {
fname <- file.choose()
table <- read.csv(fname, header=T, stringsAsFactor=F )
print(data.table(colnames(table)))
xcol_num <- as.numeric(readline('x축 컬럼 번호: '))
ycol_num <- as.numeric(readline('y축 컬럼 번호: '))
xcol <- colnames(table[xcol_num])
ycol <- colnames(table[ycol_num])
xcol2 <- table[,xcol]
ycol2 <- table[,ycol]
plot(xcol2,ycol2,
main=paste(xcol,'과',ycol,'의 산포도 그래프'),lwd=2,
xlab=xcol,ylab=ycol,col='red',pch=21,bg='red')
}
my_hist <- function() {
fname <- file.choose()
table <- read.csv(fname, header=T, stringsAsFactor=F )
print(data.table(colnames(table)))
xcol_num <- as.numeric(readline('x축 컬럼 번호: '))
xcol <- colnames(table[xcol_num])
xcol2 <- table[,xcol]
class1 <- sort(xcol2)
hist(class1 , col="yellow", density=80,      main="히스토그램 정규분포 그래프" )
par(new=T)
plot( class1, dnorm( class1, mean=mean(class1),
sd=sd(class1)),type='l', axes=FALSE, ann=FALSE,   col="red")
}
my_box <- function() {
fname <- file.choose()
table <- read.csv(fname, header=T, stringsAsFactor=F )
print(data.table(colnames(table)))
xcol_num <- as.numeric(readline('x축 컬럼 번호: '))
xcol <- colnames(table[xcol_num])
xcol2 <- table[,xcol]
boxplot(xcol2, col="green", density=80 )
}
knn_fun<-function(){
x <-  "d:/R/wisc_bc_data.csv"
y <-"diagnosis"
k_n <- 21
data1 <- read.csv(x, stringsAsFactors=FALSE)
normalize<-function(x) {
return( (x-min(x))/ ( max(x)-min(x)))
}
data1 <- data1[-1]
ncol1 <- which(colnames(data1)==y)
data1_n <- as.data.frame(lapply(data1[,-ncol1], normalize) )
mm<-round(nrow(data1_n)*2/3)
data1_train <- data1_n[1:mm, ]
data1_test  <- data1_n[(mm+1):nrow(data1_n), ]
data1_train_label <- data1[1:mm,y]
data1_test_label  <- data1[(mm+1):nrow(data1_n),y]
library(class)
result1 <- knn(train=data1_train, test=data1_test,  cl= data1_train_label, k = k_n )
prop.table( table(ifelse(data1[(mm+1):nrow(data1_n),y]==result1,"o","x" )))
fname <- file.choose()
table <- read.csv(fname, header=T, stringsAsFactor=F )
table <- table[-1]
ncol1 <- which(colnames(table)==y)
data1 <- rbind(data1,table)
data1_n <- as.data.frame(lapply(data1[,-ncol1], normalize) )
data2_test <- data1_n[nrow(data1_n),]
result2 <- knn(train=data1_train, test=data2_test,  cl= data1_train_label, k = k_n )
if (result2=='M'){
print('ML 모델이 암환자로 예측 했습니다.')
} else {
print('ML 모델이 정상환자로 예측 했습니다.')
}
}
naive_fun<-function(){
library(e1071)
flu <- read.csv("flu.csv", header=T, stringsAsFactors=TRUE)
train <- flu[1:nrow(flu),-1]
model <- naiveBayes(train[,1:4], train$flue , laplace=0)
fname <- file.choose()
test <- read.csv(fname, header=T, stringsAsFactor=F )
result <- predict( model, test, type='raw')
print(paste('독감 환자일 확률이',round(result[2]*100,digits=1),'% 입니다.'))
}
x1 <- menu( c('산포도 그래프','히스토그램 그래프','사분위수 그래프', '유방암 진단', '독감 진단') ,
title='숫자를 선택하세요: ' )
switch ( x1,
san1 = {   my_scatter()       },
san2 = {   my_hist()          },
san3 = {   my_box()           },
san4 = {   knn_fun()          },
san5 = {   naive_fun()        }
)
}
my_func()
(-11/16)*log2(11/16)+(-5/16)*log2(5/16)
(-10/16)*log2(10/16)+(-6/16)*log2(6/16)
((-2/3)*log2(2/3)+(-1/3)*log2(1/3))*3/5
skin <- read.csv('skin.csv',head=T)
skin
str(skin)
skin <- read.csv('skin.csv',head=T, stringsAsFactors = T)
str(skin)
head(skin)
install.packages('FSelector')
library(FSelector)
weights <- information.gain(cupon_react~., skin, unit='log2')
print(weights)
weights <- information.gain(cupon_react~gender, skin, unit='log2')
print(weights)
weights <- information.gain(cupon_react~skin[,-1], skin, unit='log2')
weights <- information.gain(cupon_react~., skin, unit='log2')
print(weights)
skin <- read.csv('skin.csv',head=T, stringsAsFactors = T)
head(skin)
weights <- information.gain(cupon_react~., skin, unit='log2')
print(weights)
skin <- read.csv('skin.csv',header=T, stringsAsFactors = T)
weights <- information.gain(cupon_react~., skin, unit='log2')
print(weights)
print(weights)
fat <- read.csv('fatliver2.csv',head=T,stringsAsFactors = T)
fat
str(fat)
rs2 <- information.gain(fatliver~., fat, unit='log2')
rs2 <- information.gain(FATLIVER~., fat, unit='log2')
print(rs)
rs <- information.gain(FATLIVER~., fat, unit='log2')
print(rs)
# 1. 의사결정 패키지인 C50 패키지를 설치한다.
install.packages("C50")
library(C50)
# 2. 백화점 화장품 고객 데이터를 로드하고 shuffle 한다.
skin <- read.csv("skin.csv", header=T )
nrow(skin)
skin_real_test_cust <- skin[30,  ] # 모델 생성 후 정확도를 올린 후 최종적으로 모델이 잘 맞추는지 확인하기 위해 한 건 제외
skin2 <-  skin[ 1:29, ]
nrow(skin2)
skin_real_test_cust
skin2 <- skin2[ , -1] # 고객번호를 제외시킨다.
set.seed(11)
skin2_shuffle <- skin2[sample(nrow(skin2)),    ]  # shuffle 시킴
# 3. 화장품 고객 데이터를 7대 3로 train 과 test 로 나눈다.
train_num <-  round(0.7 * nrow(skin2_shuffle), 0)
skin2_train <- skin2_shuffle[1:train_num,  ]
skin2_test  <- skin2_shuffle[(train_num+1) : nrow(skin2_shuffle), ]
nrow(skin2_train)  # 20
nrow(skin2_test)   #  9
# 4. C50 패키지를 이용해서 분류 모델을 생성한다.
skin_model <- C5.0(skin2_train[  , -6],  skin2_train$cupon_react )
# 4. C50 패키지를 이용해서 분류 모델을 생성한다.
skin_model <- C5.0(skin2_train[  , -6],  skin2_train$cupon_react )
# 2. 백화점 화장품 고객 데이터를 로드하고 shuffle 한다.
skin <- read.csv("skin.csv", header=T,stringsAsFactors = T )
nrow(skin)
skin_real_test_cust <- skin[30,  ] # 모델 생성 후 정확도를 올린 후 최종적으로 모델이 잘 맞추는지 확인하기 위해 한 건 제외
skin2 <-  skin[ 1:29, ]
nrow(skin2)
skin_real_test_cust
skin2 <- skin2[ , -1] # 고객번호를 제외시킨다.
set.seed(11)
skin2_shuffle <- skin2[sample(nrow(skin2)),    ]  # shuffle 시킴
# 3. 화장품 고객 데이터를 7대 3로 train 과 test 로 나눈다.
train_num <-  round(0.7 * nrow(skin2_shuffle), 0)
skin2_train <- skin2_shuffle[1:train_num,  ]
skin2_test  <- skin2_shuffle[(train_num+1) : nrow(skin2_shuffle), ]
nrow(skin2_train)  # 20
nrow(skin2_test)   #  9
# 4. C50 패키지를 이용해서 분류 모델을 생성한다.
skin_model <- C5.0(skin2_train[,-6],  skin2_train$cupon_react )
# 5. 위에서 만든 skin_model 를 이용해서 테스테 데이터의 라벨을 예측하시오!
skin2_result  <- predict( skin_model , skin2_test[  , -6])
# 5. 위에서 만든 skin_model 를 이용해서 테스테 데이터의 라벨을 예측하시오!
skin2_result  <- predict( skin_model , skin2_test[  , -6])
skin2_test
# 4. C50 패키지를 이용해서 분류 모델을 생성한다.
skin_model <- C5.0(skin2_train[,-6],  skin2_train$cupon_react )
# 5. 위에서 만든 skin_model 를 이용해서 테스테 데이터의 라벨을 예측하시오!
skin2_result  <- predict( skin_model , skin2_test[  , -6])
# 4. C50 패키지를 이용해서 분류 모델을 생성한다.
skin_model <- C5.0(skin2_train[,-6],  skin2_train$cupon_react,type='class' )
# 5. 위에서 만든 skin_model 를 이용해서 테스테 데이터의 라벨을 예측하시오!
skin2_result  <- predict( skin_model , skin2_test[  , -6])
# 4. C50 패키지를 이용해서 분류 모델을 생성한다.
skin_model <- C5.0(skin2_train[,-6],  skin2_train$cupon_react )
# 5. 위에서 만든 skin_model 를 이용해서 테스테 데이터의 라벨을 예측하시오!
skin2_result  <- predict( skin_model , skin2_test[  , -6],type='class')
# 5. 위에서 만든 skin_model 를 이용해서 테스테 데이터의 라벨을 예측하시오!
skin2_result  <- predict( skin_model , skin2_test[,-6])
skin <- read.csv("skin.csv", header=T ,stringsAsFactors = TRUE)
str(skin)
nrow(skin)
skin_real_test_cust <- skin[30,  ]  # 나중에 모델 만들고 정확도를 올린후에
# 최종적으로 모델이 잘 맞추는지 확인하려
# 한건 제외 시킨다.
skin2 <-  skin[ 1:29, ]
nrow(skin2)
skin_real_test_cust
skin2 <- skin2[ , -1] # 고객번호를 제외시킨다.
set.seed(11)
skin2_shuffle <- skin2[sample(nrow(skin2)),    ]  # shuffle 시킴
train_num <-  round(0.7 * nrow(skin2_shuffle), 0)
skin2_train <- skin2_shuffle[1:train_num,  ]
skin2_test  <- skin2_shuffle[(train_num+1) : nrow(skin2_shuffle), ]
nrow(skin2_train)  # 20
nrow(skin2_test)   #  9
library(C50)
skin_model <- C5.0(skin2_train[  , -6],  skin2_train$cupon_react )
skin2_result  <- predict( skin_model , skin2_test[  , -6])
skin <- read.csv("skin.csv", head=T ,stringsAsFactors = T)
skin_real_test_cust <- skin[30,  ]  # 나중에 모델 만들고 정확도를 올린후에
# 최종적으로 모델이 잘 맞추는지 확인하려
# 한건 제외 시킨다.
skin2 <-  skin[ 1:29, ]
skin_real_test_cust
skin2 <- skin2[ , -1] # 고객번호를 제외시킨다.
set.seed(11)
skin2_shuffle <- skin2[sample(nrow(skin2)),    ]  # shuffle 시킴
train_num <-  round(0.7 * nrow(skin2_shuffle), 0)
skin2_train <- skin2_shuffle[1:train_num,  ]
skin2_test  <- skin2_shuffle[(train_num+1) : nrow(skin2_shuffle), ]
skin_model <- C5.0(skin2_train[  , -6],  skin2_train$cupon_react )
skin2_result  <- predict( skin_model , skin2_test[  , -6])
library(gmodels)
CrossTable( skin2_test[  , 6],  skin2_result )
skin_model2 <- C5.0(skin2_train[  , -6],  skin2_train$cupon_react,trials=10 )
skin2_result  <- predict( skin_model , skin2_test[  , -6])
CrossTable( skin2_test[  , 6],  skin2_result )
skin2_result  <- predict( skin_model2 , skin2_test[  , -6])
CrossTable( skin2_test[  , 6],  skin2_result )
skin_model2 <- C5.0(skin2_train[  , -6],  skin2_train$cupon_react,trials=10 )
skin2_result  <- predict( skin_model2 , skin2_test[  , -6])
CrossTable( skin2_test[  , 6],  skin2_result )
skin <- read.csv("skin.csv", head=T ,stringsAsFactors = T)
skin_real_test_cust <- skin[30,  ]  # 나중에 모델 만들고 정확도를 올린후에 최종적으로 모델이 잘 맞추는지 확인하려 한건 제외 시킨다.
skin2 <-  skin[ 1:29, ]
skin_real_test_cust
skin2 <- skin2[ , -1] # 고객번호를 제외시킨다.
set.seed(11)
skin2_shuffle <- skin2[sample(nrow(skin2)),    ]  # shuffle 시킴
train_num <-  round(0.7 * nrow(skin2_shuffle), 0)
skin2_train <- skin2_shuffle[1:train_num,  ]
skin2_test  <- skin2_shuffle[(train_num+1) : nrow(skin2_shuffle), ]
library(C50)
skin_model <- C5.0(skin2_train[  , -6],  skin2_train$cupon_react )
skin_model2 <- C5.0(skin2_train[  , -6],  skin2_train$cupon_react,trials=10 )
skin2_result  <- predict( skin_model2 , skin2_test[  , -6])
CrossTable( skin2_test[  , 6],  skin2_result )
skin_model2 <- C5.0(skin2_train[  , -6],  skin2_train$cupon_react,trials=14 )
skin2_result  <- predict( skin_model2 , skin2_test[  , -6])
CrossTable( skin2_test[  , 6],  skin2_result )
skin <- read.csv("skin.csv", head=T ,stringsAsFactors = T)
skin_real_test_cust <- skin[30,  ]  # 나중에 모델 만들고 정확도를 올린후에 최종적으로 모델이 잘 맞추는지 확인하려 한건 제외 시킨다.
skin2 <-  skin[ 1:29, ]
skin_real_test_cust
skin2 <- skin2[ , -1] # 고객번호를 제외시킨다.
set.seed(20)
skin2_shuffle <- skin2[sample(nrow(skin2)),    ]  # shuffle 시킴
train_num <-  round(0.7 * nrow(skin2_shuffle), 0)
skin2_train <- skin2_shuffle[1:train_num,  ]
skin2_test  <- skin2_shuffle[(train_num+1) : nrow(skin2_shuffle), ]
skin_model2 <- C5.0(skin2_train[  , -6],  skin2_train$cupon_react,trials=10 )
skin2_result  <- predict( skin_model2 , skin2_test[  , -6])
CrossTable( skin2_test[  , 6],  skin2_result )
credit <- read.csv("credit.csv",head=T)
str(credit)
credit <- read.csv("credit.csv",head=T,stringsAsFactors = T)
str(credit)
prop.table( table(credit$default)  )
summary( credit$amount)
str(credit)
set.seed(31)
credit_shuffle <-  credit[ sample( nrow(credit) ),  ]
train_num <- round( 0.9 * nrow(credit_shuffle), 0)
credit_train <- credit_shuffle[1:train_num ,  ]
credit_test  <- credit_shuffle[(train_num+1) : nrow(credit_shuffle),  ]
credit_model <- C5.0( credit_train[ ,-17] , credit_train[  , 17] )
credit_result <-  predict( credit_model, credit_test[  , -17] )
CrossTable(  credit_test[   , 17], credit_result )
#                ↑                     ↑
#              실제                   예측
rs <- CrossTable(  credit_test[   , 17], credit_result )
rs
rs[1,1]
credit_model
summary(credit_model)
skin_model
skin_model <- C5.0(skin2_train[  , -6],  skin2_train$cupon_react )
skin_model
summary(skin_model)
((-2/3)*log2(2/3)+(-1/3)*log2(1/3))*3/5
install.packages('caret')
install.packages('rpart')
install.packages("rpart")
install.packages('rpart.plot')
credit = read.csv('credit.csv',header=T,stringsAsFactors = T)
library(caret)
set.seed(5)
intrain = createDataPartition(credit$default,p=0.9,list=F)
credit_train = credit[intrain,]
credit_test = credit[-intrain,]
nrow(credit_train) # 900
nrow(credit_test) # 100
library(C50)
credit_model = C5.0(default~.,data=credit_train,trials=24) # 24 : 0.87
credit_result = predict(credit_model,credit_test[,-17])
library(gmodels)
x = CrossTable(credit_test[,17],credit_result)
library(rpart)
library(rpart.plot)
rpartmod = rpart(default~., data=credit_train, method='class')
rpart.plot(rpartmod)
x$prop.tbl[1]+x$prop.tbl[4] # 0.87
dev.new()
rpart.plot(rpartmod)
savePlot('dcs_tree.png', type='png')
