{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>■ 모델성능개선</b>\n",
    "### <b>※ 데이터 분석 5가지 단계</b>\n",
    "    1. 데이터 수집\n",
    "    2. 데이터 탐색(결측치, 이상치, 시각화->종속변수가 정규성 확인)\n",
    "    3. 머신러닝 모델 훈련\n",
    "    4. 모델 성능 평가 (정확도, 카파지수(일치도), 민감도, 특이도, 정밀도, 재현율, F척도, ROCC, AUC)\n",
    "                                               Y축: 민감도     공격적예측\n",
    "                                               X축: 1-특이도   보수적예측\n",
    "\n",
    "### <b>□ 모델성능개선을 위한 방법</b>\n",
    "    1. K-holdout\n",
    "    2. caret을 통한 자동튜닝\n",
    "    3. 앙상블(Ensemble)\n",
    "    4. 배깅(Bagging)\n",
    "    5. 부스팅(Boosting)\n",
    "\n",
    "### <b>■ K-Holdout</b>\n",
    "    1. train data와 test data를 나눌 때 비율은 8:2, 7:3 등으로 시행\n",
    "![k-ho](https://mblogthumb-phinf.pstatic.net/MjAyMDAxMTBfMjE4/MDAxNTc4NjE5NTA0NTc5.Ub3YttdSVVHvReojJPpxGQbugP-xK_R6oG64vxLW0A0g.sDE6aGiiaCyiIXito3qhJgysytoI2VO6NUt8zE9Uv_Eg.PNG.sjc02183/image.png?type=w800)\n",
    "<center><b>1:1 비율 시행 시 training 양이 적음 -> under fitting 발생</b><br>\n",
    "    <b>2:1 비율 시행 시 training data 양이 많으므로 훈련 data에만 최적화된 모델이 생성 -> over fitting 발생</b></center><br><br>\n",
    "    \n",
    "![validation](https://blogfiles.pstatic.net/MjAxOTExMDlfMjA3/MDAxNTczMzAzOTU2MDIy.phxU3c8U0hnkP67vbwztLyA7byhQ7ePjuKa04YJCp0Ag.M8p1TZapTG0aItcZzfKQvPwGuK6P9z0qBZDIMPCBmZMg.PNG.sjc02183/image.png?type=w1)\n",
    "    <center><b>Validation : training set의 일부를 모델의 성능 평가를 위해 희생</b></center>\n",
    "    \n",
    "#### <b>■ Validation을 사용하는 이유?</b>\n",
    "    모델의 성능 평가를 위해서 \n",
    "        훈련을 한 후 만들어진 모형이 잘 예측을 하는지 그 성능을 평가하기 위해서 사용\n",
    "        \n",
    "#### <b>■ Validation data로 모델의 성능을 평가하면 좋은점</b>\n",
    "    1. test accuracy를 가늠해 볼 수 있다\n",
    "    2. over fitting을 막을 수 있다.\n",
    "        training 정확도 ≒ Validation 정확도\n",
    "            -> Generalization\n",
    "            \n",
    "#### <b>■ train data의 양이 작을 떄는 어떻게 하는가?</b>\n",
    "    Cross Validation을 사용\n",
    "    \n",
    "### <b>■ K-fold 교차 검정 : 모든 training data를 training과 validation으로 사용</b>\n",
    "![kfold](https://miro.medium.com/max/1202/1*PdwlCactbJf8F8C7sP-3gw.png)\n",
    "<center><b> 1-fold : 첫번째 모델(Fold1)은 첫번째 폴드를 테스로 활용하고 나머지 Fold2~5까지를 훈련 세트로 사용</b><br>\n",
    "    $\\vdots$<br>\n",
    "    <b>반복 시행하면서 hyper parameter 도출</b></center>\n",
    "\n",
    "    1. kNN : k\n",
    "    2. naiveBeyes : Laplace\n",
    "    3. Decision Tree : trials\n",
    "    4. neural netword : hidden, learning rate\n",
    "    5. SVM : lambda, gamma\n",
    "    \n",
    "![bpara](https://scikit-learn.org/stable/_images/grid_search_workflow.png)\n",
    "\n",
    "    각각의 k-fold가 모델이 되고 data set에서 test data는 따로 남겨 둔 후 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    지난번 분류를 위해 사용한 ML 모델 : 의사결정트리\n",
    "    지난번 훈련시킬 때 데이터 나눔 방식 : 훈련과 테스트로만 분리\n",
    "    \n",
    "    데이터 나눔 방식:\n",
    "        1. 훈련 데이터 75%(훈련 50%, 검정 25%)\n",
    "        2. 테스트 데이터 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ■ 홀드 아웃 과 k 홀드 아웃 \n",
    "## Estimating Future Performance ----\n",
    "# partitioning data\n",
    "\n",
    "#install.packages(\"caret\") \n",
    "library(caret)\n",
    "credit <- read.csv(\"credit.csv\") # 독일 은행의 채무 불이행자를 예측하기 위한 데이터 \n",
    "\n",
    "# Holdout method\n",
    "# using random IDs\n",
    "\n",
    "random_ids <- order(runif(1000)) # 난수 1000개 생성 \n",
    "\n",
    "credit_train <- credit[random_ids[1:500],]  # 훈련 50%\n",
    "credit_validate <- credit[random_ids[501:750], ] # 검정 25%\n",
    "credit_test <- credit[random_ids[751:1000], ]  # 테스트 25%\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    위 처럼 시행시 클래스가 2개(채무이행자, 채무 불이행자)라면 어떤 클래스에 편중되는 문제가 발생\n",
    "    훈련데이터: 75% 중 채무이행자:채무 불이행자 = 70:30\n",
    "    테스트 데이터: 25% 중 채무이행자:채무 불이행자 = 70:30 로 분류\n",
    "    \n",
    "    이를 해결하는 방법이 층별 랜덤 샘플링 \n",
    "        createDataPartition 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using caret function\n",
    "\n",
    "in_train <- createDataPartition(credit$default, p = 0.75, list = FALSE) # credit$default : 라벨\n",
    "\n",
    "credit_train <- credit[in_train, ] # 훈련 데이터 구성\n",
    "credit_test <- credit[-in_train, ] # 테스트 데이터 구성 \n",
    "\n",
    "# 10-fold CV\n",
    "\n",
    "folds <- createFolds(credit$default, k = 10) # 전체 10폴드 교차검증을 수행하기 위해 샘플링 된 인덱스\n",
    "str(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit01_test <- credit[folds$Fold01, ]\n",
    "credit01_train <- credit[-folds$Fold01, ]\n",
    "\n",
    "전체 10폴드 교차검증을 수행하려면 이 단계는 10회 반복되어야한다. \n",
    "\n",
    "## Automating 10-fold CV for a C5.0 Decision Tree using lapply() ----\n",
    "\n",
    "library(caret)\n",
    "library(C50)\n",
    "library(irr)\n",
    "\n",
    "credit <- read.csv(\"credit.csv\")\n",
    "\n",
    "set.seed(123)\n",
    "\n",
    "folds <- createFolds(credit$default, k = 10)\n",
    "cv_results <- lapply(folds, function(x) {\n",
    "  credit_train <- credit[-x, ]\n",
    "  credit_test <- credit[x, ]\n",
    "  credit_model <- C5.0(default ~ ., data = credit_train)\n",
    "  credit_pred <- predict(credit_model, credit_test)\n",
    "  credit_actual <- credit_test$default\n",
    "  kappa <- kappa2(data.frame(credit_actual, credit_pred))$value\n",
    "  return(kappa)\n",
    "})\n",
    "\n",
    "str(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 문제295. (점심시간 문제)저자는 전체 데이터를 다 써서 k-foldout 검정교차를 했지만 우리는 80%만 사용해서 10 foldout 교차검정을 할 수 있도록 코드를 수정하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(C50)\n",
    "library(irr)\n",
    "\n",
    "credit <- read.csv(\"credit.csv\",stringsAsFactors = T)\n",
    "\n",
    "#set.seed(123)\n",
    "#random_ids <- order(runif(800))\n",
    "#credit <- credit[random_ids[1:800],]\n",
    "\n",
    "in_train <- createDataPartition(credit$default,p = 0.8, list = FALSE) \n",
    "in_train\n",
    "credit_train <- credit[in_train, ] # 훈련 데이터 구성\n",
    "credit_test <- credit[-in_train, ] # 테스트 데이터 구성\n",
    "\n",
    "nrow(credit_train) #601\n",
    "nrow(credit_test) #199\n",
    "\n",
    "folds <- createFolds(credit$default, k = 10)\n",
    "\n",
    "cv_results <- lapply(folds, function(x) {\n",
    "  credit_train <- credit[-x, ]\n",
    "  credit_test <- credit[x, ]\n",
    "  credit_model <- C5.0(default ~ ., data = credit_train)\n",
    "  credit_pred <- predict(credit_model, credit_test)\n",
    "  credit_actual <- credit_test$default\n",
    "  kappa <- kappa2(data.frame(credit_actual, credit_pred))$value\n",
    "  return(kappa)\n",
    "})\n",
    "\n",
    "str(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>■ 머신러닝 데이터 분석 시 k-fold를 사용하는 목적</b>\n",
    "    1. 데이터를 전부 다 써서 k fold하고 최고의 하이퍼 파라미터를 알아내고 어떤 모델이 더 좋은지 알아내기 위한게 k fold의 주 목적\n",
    "    2. 훈련 데이터와 테스트 데이터로 전체 데이터를 나누고 테스트 데이터의 정확도를 확인하고 싶을 때 createDataPartition으로 확인\n",
    "```R\n",
    "in_train <- createDataPartition(credit$default,p=0.75,list=FALSE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 문제296. 독일 은행 채무 불이행자를 예측하기 위한 의사결정트리 모델의 성능을 높이기 위해 k-fold를 이용하는데 이번에는 kappa지수가 아니라 정확도로 출력되게 하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T05:10:15.804826Z",
     "start_time": "2020-07-07T05:10:00.861Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/knitwill/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n",
      "also installing the dependency 'lpSolve'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'lpSolve' successfully unpacked and MD5 sums checked\n",
      "package 'irr' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\knitwill\\AppData\\Local\\Temp\\Rtmp0WyeTC\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages('irr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T05:13:42.085593Z",
     "start_time": "2020-07-07T05:13:41.340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 10\n",
      " $ Fold01: num 0.76\n",
      " $ Fold02: num 0.81\n",
      " $ Fold03: num 0.72\n",
      " $ Fold04: num 0.74\n",
      " $ Fold05: num 0.75\n",
      " $ Fold06: num 0.76\n",
      " $ Fold07: num 0.67\n",
      " $ Fold08: num 0.66\n",
      " $ Fold09: num 0.65\n",
      " $ Fold10: num 0.76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.728"
      ],
      "text/latex": [
       "0.728"
      ],
      "text/markdown": [
       "0.728"
      ],
      "text/plain": [
       "[1] 0.728"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(caret)\n",
    "library(C50)\n",
    "library(irr)\n",
    "\n",
    "credit <- read.csv(\"credit.csv\",stringsAsFactors = T)\n",
    "\n",
    "set.seed(123)\n",
    "folds <- createFolds(credit$default, k = 10)\n",
    "\n",
    "cv_results <- lapply(folds, function(x) {\n",
    "  credit_train <- credit[-x, ]\n",
    "  credit_test <- credit[x, ]\n",
    "  credit_model <- C5.0(default ~ ., data = credit_train)\n",
    "  credit_pred <- predict(credit_model, credit_test)\n",
    "  credit_actual <- credit_test$default\n",
    "  \n",
    "  x <- data.frame(credit_actual, credit_pred)\n",
    "  rs <- sum(x$credit_actual==x$credit_pred)/length(x$credit_actual==x$credit_pred)\n",
    "  return(rs)\n",
    "})\n",
    "str(cv_results)\n",
    "mean(unlist(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 문제297. 위의 의사결정트리 머신러닝 모델의 최적의 하이퍼 파라미터가 무엇인지 알아내기 위해서 trials를 주고 실행해보시오\n",
    "    trials=50으로 실행해보고 정확도의 평균값을 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T05:14:58.732512Z",
     "start_time": "2020-07-07T05:14:54.746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 10\n",
      " $ Fold01: num 0.74\n",
      " $ Fold02: num 0.77\n",
      " $ Fold03: num 0.72\n",
      " $ Fold04: num 0.76\n",
      " $ Fold05: num 0.77\n",
      " $ Fold06: num 0.8\n",
      " $ Fold07: num 0.76\n",
      " $ Fold08: num 0.72\n",
      " $ Fold09: num 0.73\n",
      " $ Fold10: num 0.67\n",
      "[1] 0.744\n"
     ]
    }
   ],
   "source": [
    "library(caret)\n",
    "library(C50)\n",
    "library(irr)\n",
    "\n",
    "credit <- read.csv(\"credit.csv\",stringsAsFactors = T)\n",
    "\n",
    "set.seed(123)\n",
    "folds <- createFolds(credit$default, k = 10)\n",
    "\n",
    "cv_results <- lapply(folds, function(x) {\n",
    "  credit_train <- credit[-x, ]\n",
    "  credit_test <- credit[x, ]\n",
    "  credit_model <- C5.0(default ~ ., data = credit_train,trials=50)\n",
    "  credit_pred <- predict(credit_model, credit_test)\n",
    "  credit_actual <- credit_test$default\n",
    "  \n",
    "  x <- data.frame(credit_actual, credit_pred)\n",
    "  rs <- sum(x$credit_actual==x$credit_pred)/length(x$credit_actual==x$credit_pred)\n",
    "  return(rs)\n",
    "})\n",
    "str(cv_results)\n",
    "print(mean(unlist(cv_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ caret을 이용한 모델 자동튜닝\n",
    "    이전에는 머신러닝 모델의 성능을 높이기 위해서 우리가 직접 모델의 성능을 높이는 하이퍼 파라미터(예: c50의 trials)를 직접 알아내야 함\n",
    "    caret을 이용하면 이 패키지가 알아서 최적의 파라미터를 찾아준다.\n",
    "    \n",
    "http://topepo.github.io/caret/available-models.html\n",
    "    \n",
    "    의사결정트리의 튜닝은 model, trials, winnow 설정에 대해 3의 3제곱(27개)의 조합으로 정확도를 각각 계산해서 가장 정확도가 높은 조합을 찾아내야하는데\n",
    "    caret 패키지가 이를 자동으로 찾아준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T05:31:05.974312Z",
     "start_time": "2020-07-07T05:30:55.026Z"
    }
   },
   "outputs": [],
   "source": [
    "# caret 패키지 사용\n",
    "credit <- read.csv('credit.csv',stringsAsFactors = T)\n",
    "set.seed(300)\n",
    "# C5.0 의 하이퍼 파라미터인 trials, winnow, model의 27개의 조합에 대한 각각의 정확도를 구하는 작업\n",
    "m <- train(default~., data=credit, method='C5.0')\n",
    "m\n",
    "\n",
    "p <- predict(m,credit)\n",
    "table(p,credit$default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>■ 튜닝 절차 customizing하기</b>\n",
    "    튜닝 절차를 customizing해서 성능 향상 가능\n",
    "        1. 기존 방법:\n",
    "```R\n",
    "m <- train(default~., data=credit,method='C5.0')\n",
    "```\n",
    "        2. customzing\n",
    "```R\n",
    "ctrl <- trainControl(method='cv',number=10,selectionFunction='oneSE')\n",
    "# method='cv'               : k-fold 교차검증\n",
    "# number=10                 : fold 수\n",
    "# selectionFunction='oneSE' : 다양한 후보 중에서 최적의 모델을 선택하는 방법 중 하나\n",
    "    best  : 후보 중 단순히 성능척도 값 중 최고값을 갖는 후보를 선택(default)\n",
    "    oneSE : 최고 성능의 1 표준오차내의 가장 단순한 후보 선택\n",
    "    tolerance : 사용자 지정 비율 내에 가장 단순한 후보 선택\n",
    "grid <- expand.grid(.model='tree',\n",
    "                    .trials=c(1,5,10,15,20,25,30,35), # trials를 8개로 제한하겠다\n",
    "                    .winnow='FALSE')\n",
    "m_test <- train(default~., data=credit, method='C5.0',\n",
    "                metric='kappa',\n",
    "                trControl=ctrl,\n",
    "                truneGrid=grid)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T06:09:13.245723Z",
     "start_time": "2020-07-07T06:08:22.219Z"
    }
   },
   "outputs": [],
   "source": [
    "m <- train(default~., data=credit,method='C5.0')\n",
    "ctrl <- trainControl(method='cv',number=10,selectionFunction='oneSE')\n",
    "grid <- expand.grid(.model='tree',\n",
    "                    .trials=c(1,5,10,15,20,25,30,35), # trials를 8개로 제한하겠다\n",
    "                    .winnow='FALSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T06:05:28.100252Z",
     "start_time": "2020-07-07T06:05:11.511Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in train.default(x, y, weights = w, ...):\n",
      "\"The metric \"kappa\" was not in the result set. Accuracy will be used instead.\""
     ]
    }
   ],
   "source": [
    "m <- train(default~., data=credit, method='C5.0',\n",
    "           metric='kappa',\n",
    "           trControl=ctrl,\n",
    "           truneGrid=grid)\n",
    "p <- predict(m_test, credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T06:12:52.361756Z",
     "start_time": "2020-07-07T06:12:52.331Z"
    }
   },
   "outputs": [],
   "source": [
    "ctrl <-  trainControl( method=\"cv\", number=10,\n",
    "                      selectionFunction=\"oneSE\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T06:13:53.981390Z",
     "start_time": "2020-07-07T06:13:38.106Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"'trials' should be <= 6 for this object. Predictions generated using 6 trials\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "     \n",
       "p      no yes\n",
       "  no  696  12\n",
       "  yes   4 288"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid <-  expand.grid( .model=\"tree\",.trials= c(1, 5, 10, 15, 20, 25, 30, 35),.winnow=\"FALSE\" )\n",
    "m <- train( default~ . , data=credit, method=\"C5.0\",metric=\"Kappa\",trControl= ctrl,truneGrid= grid )\n",
    "p <- predict( m, credit )\n",
    "table( p, credit$default )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
